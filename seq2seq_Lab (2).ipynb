{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DW3n3H7A6zsl"
      },
      "source": [
        "# Seq2seq для машинного перевода"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В этом блокноте рассматриваются некоторые подходы к задаче машинного перевода с помощью\n",
        "\n",
        "* Рекуррентных сетей\n",
        "* Рекуррентных сетей с механизмом внимания\n",
        "* Трасформеров\n",
        "\n",
        "Первый и последний подходы уже реализованы. Вам предлагается реализовать второй подход, а именно интегрировать механизм внимания в рекуррентную НС. Для лучшего понимания рекомендуем ознакомиться [со следющей статьей](https://arxiv.org/pdf/1409.0473). Какой конкретно тип механизма внимания реализовывать остается на выбор студенту.\n",
        "\n",
        "Для оценок трех рассмотренных подходов реализовать метрику BLEU. В качестве тестовой выборки можно использовать валидационный набор. Или произвести требуемое разделение самостоятельно.\n",
        "\n",
        "В качестве резюме (на 3 балла):\n",
        "\n",
        "1. Разобраться в задаче и в коде\n",
        "2. Добавить внимание к рекуррентной сети\n",
        "3. Реализовать BLEU\n",
        "4. Сравнить полученные 3 модели между собой.\n",
        "5. **Опционально (+1 балл)**: продемонстрировать alignment между словами на исходном и целевом языках (аналогично Figure 3 в предложенной статье).\n",
        "6. **Опционально (+1 балл)**: сравнить 3 полученных модели (по метрике) между собой на парах различной длины. Например, вычислить метрики на коротких, средних и длинных предложениях. Если средних/длинных предложений нет в выборке -- сгенерировать самостоятельно, например через LLM."
      ],
      "metadata": {
        "id": "enGzi87CCVwS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Yj0-uS06zsn"
      },
      "source": [
        "# Загрузка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2x5ZTBy86zsn",
        "outputId": "90ddd7fb-c499-4ca1-e906-5e7e7405a9f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-04 12:01:47--  http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.26.207, 172.217.204.207, 172.217.203.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.26.207|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2638744 (2.5M) [application/zip]\n",
            "Saving to: ‘spa-eng.zip’\n",
            "\n",
            "\rspa-eng.zip           0%[                    ]       0  --.-KB/s               \rspa-eng.zip         100%[===================>]   2.52M  --.-KB/s    in 0.009s  \n",
            "\n",
            "2025-06-04 12:01:47 (281 MB/s) - ‘spa-eng.zip’ saved [2638744/2638744]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
        "!unzip -q spa-eng.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKCfzcx36zsn"
      },
      "outputs": [],
      "source": [
        "text_file = \"spa-eng/spa.txt\"\n",
        "with open(text_file) as f:\n",
        "    lines = f.read().split(\"\\n\")[:-1]\n",
        "text_pairs = []\n",
        "for line in lines:\n",
        "    english, spanish = line.split(\"\\t\")\n",
        "    spanish = \"[start] \" + spanish + \" [end]\"\n",
        "    text_pairs.append((english, spanish))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0P__Dih6zso",
        "outputId": "18e0f7d4-4a3f-4213-be76-b268b541b7ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('I was about to suggest the same thing.', '[start] Estaba a punto de sugerir lo mismo. [end]')\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "print(random.choice(text_pairs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jb76u2yM6zso"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "random.shuffle(text_pairs)\n",
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples:num_train_samples + num_val_samples]\n",
        "test_pairs = text_pairs[num_train_samples + num_val_samples:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvBYqlQT6zso"
      },
      "source": [
        "**Векторизация пар**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOr5m_4L6zso"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import string\n",
        "import re\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "strip_chars = string.punctuation + \"¿\"\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "\n",
        "def custom_standardization(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(\n",
        "        lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n",
        "\n",
        "vocab_size = 15000\n",
        "sequence_length = 20\n",
        "\n",
        "source_vectorization = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "target_vectorization = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        "    standardize=custom_standardization,\n",
        ")\n",
        "train_english_texts = [pair[0] for pair in train_pairs]\n",
        "train_spanish_texts = [pair[1] for pair in train_pairs]\n",
        "source_vectorization.adapt(train_english_texts)\n",
        "target_vectorization.adapt(train_spanish_texts)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "real_vocab_size = target_vectorization.vocabulary_size()\n",
        "print(f\"Реальный размер словаря: {real_vocab_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QliqkBm_GsYx",
        "outputId": "a3b2c5ca-cae1-423b-f433-fb4297b2f954"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Реальный размер словаря: 15000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l02mPwAo6zso"
      },
      "source": [
        "**Подготовка датасетов**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-58r_2Z6zso"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "\n",
        "def format_dataset(eng, spa):\n",
        "    eng = source_vectorization(eng)\n",
        "    spa = target_vectorization(spa)\n",
        "    return ({\n",
        "        \"english\": eng,\n",
        "        \"spanish\": spa[:, :-1],\n",
        "    }, spa[:, 1:])\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    eng_texts, spa_texts = zip(*pairs)\n",
        "    eng_texts = list(eng_texts)\n",
        "    spa_texts = list(spa_texts)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset, num_parallel_calls=4)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()\n",
        "\n",
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ks4BnfL6zsp",
        "outputId": "18f4ae4c-a5c5-4d5f-c622-7a1450a4d75d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs['english'].shape: (16, 20)\n",
            "inputs['spanish'].shape: (16, 20)\n",
            "targets.shape: (16, 20)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f\"inputs['english'].shape: {inputs['english'].shape}\")\n",
        "    print(f\"inputs['spanish'].shape: {inputs['spanish'].shape}\")\n",
        "    print(f\"targets.shape: {targets.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lqbdLbR6zsp"
      },
      "source": [
        "# RNN сеть"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRMgWreP6zsp"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "embed_dim = 256\n",
        "latent_dim = 1024\n",
        "\n",
        "source = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n",
        "x = layers.Embedding(vocab_size, embed_dim, mask_zero=True)(source)\n",
        "encoded_source = layers.Bidirectional(\n",
        "    layers.GRU(latent_dim), merge_mode=\"sum\")(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-FqV3LD6zsq"
      },
      "outputs": [],
      "source": [
        "past_target = keras.Input(shape=(None,), dtype=\"int64\", name=\"spanish\")\n",
        "x = layers.Embedding(vocab_size, embed_dim, mask_zero=True)(past_target)\n",
        "decoder_gru = layers.GRU(latent_dim, return_sequences=True)\n",
        "x = decoder_gru(x, initial_state=encoded_source)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "target_next_step = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "seq2seq_rnn = keras.Model([source, past_target], target_next_step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDZ_S0346zsq",
        "outputId": "397b6ba5-7f68-49f6-f40d-91babb89ad45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 165ms/step - accuracy: 0.1520 - loss: 5.2623 - val_accuracy: 0.1561 - val_loss: 3.8936\n",
            "Epoch 2/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 169ms/step - accuracy: 0.1609 - loss: 3.8834 - val_accuracy: 0.1875 - val_loss: 3.2585\n",
            "Epoch 3/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 169ms/step - accuracy: 0.1860 - loss: 3.3265 - val_accuracy: 0.2078 - val_loss: 2.8806\n",
            "Epoch 4/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 168ms/step - accuracy: 0.2034 - loss: 2.9504 - val_accuracy: 0.2219 - val_loss: 2.6350\n",
            "Epoch 5/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 168ms/step - accuracy: 0.2177 - loss: 2.6586 - val_accuracy: 0.2325 - val_loss: 2.4511\n",
            "Epoch 6/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 169ms/step - accuracy: 0.2302 - loss: 2.4235 - val_accuracy: 0.2408 - val_loss: 2.3162\n",
            "Epoch 7/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 169ms/step - accuracy: 0.2402 - loss: 2.2271 - val_accuracy: 0.2461 - val_loss: 2.2281\n",
            "Epoch 8/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 169ms/step - accuracy: 0.2494 - loss: 2.0615 - val_accuracy: 0.2512 - val_loss: 2.1519\n",
            "Epoch 9/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 169ms/step - accuracy: 0.2569 - loss: 1.9190 - val_accuracy: 0.2556 - val_loss: 2.0869\n",
            "Epoch 10/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 170ms/step - accuracy: 0.2636 - loss: 1.7982 - val_accuracy: 0.2582 - val_loss: 2.0451\n",
            "Epoch 11/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 169ms/step - accuracy: 0.2695 - loss: 1.6896 - val_accuracy: 0.2605 - val_loss: 2.0100\n",
            "Epoch 12/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 170ms/step - accuracy: 0.2747 - loss: 1.5950 - val_accuracy: 0.2625 - val_loss: 1.9827\n",
            "Epoch 13/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 169ms/step - accuracy: 0.2796 - loss: 1.5123 - val_accuracy: 0.2641 - val_loss: 1.9628\n",
            "Epoch 14/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 169ms/step - accuracy: 0.2839 - loss: 1.4400 - val_accuracy: 0.2652 - val_loss: 1.9500\n",
            "Epoch 15/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 169ms/step - accuracy: 0.2880 - loss: 1.3724 - val_accuracy: 0.2664 - val_loss: 1.9297\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a7d401fb850>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "seq2seq_rnn.compile(\n",
        "    optimizer=\"rmsprop\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"])\n",
        "seq2seq_rnn.fit(train_ds, epochs=15, validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfBANm9y6zsq"
      },
      "source": [
        "**Пример перевода с помощью RNN сети**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxjFd4nf6zsr",
        "outputId": "d04e34ea-609f-4980-d5e6-df84c5e025c8",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "Tom spilled his drink.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "[start] tom [UNK] su bebida [end]\n",
            "-\n",
            "Anything can happen on TV.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "[start] cualquier cosa puede ver en la televisión [end]\n",
            "-\n",
            "This tree is about as tall as that one.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "[start] este árbol es tan grande como ese [end]\n",
            "-\n",
            "Lock the door!\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "[start] cierra la puerta de la puerta [end]\n",
            "-\n",
            "Tom told Mary she should study harder.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "[start] tom le dijo a mary que debería estudiar más [end]\n",
            "-\n",
            "I know how old Tom is.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "[start] sé cómo es tom [end]\n",
            "-\n",
            "This time is different.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "[start] este tiempo es diferente [end]\n",
            "-\n",
            "I'll call Tom tomorrow.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "[start] mañana a llamar a tom mañana [end]\n",
            "-\n",
            "I need more power.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "[start] necesito más [UNK] [end]\n",
            "-\n",
            "I'll dream about you.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "[start] yo te [UNK] en ti [end]\n",
            "-\n",
            "I miss it.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "[start] me [UNK] [end]\n",
            "-\n",
            "We need to figure it out.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "[start] tenemos que [UNK] [end]\n",
            "-\n",
            "Everybody loves Tom.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "[start] todos quieren a tom [end]\n",
            "-\n",
            "The extremists refused to negotiate.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "[start] el [UNK] se negó a [UNK] [end]\n",
            "-\n",
            "It is difficult for me to answer the question.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "[start] me es difícil para responder a la pregunta [end]\n",
            "-\n",
            "I just need to know who Tom is.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "[start] solo necesito saber quién es tom [end]\n",
            "-\n",
            "From what he says, I don't think we should go.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "[start] por qué me ha dicho que no debería ir [end]\n",
            "-\n",
            "I come here every Monday.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "[start] vengo aquí todos los días [end]\n",
            "-\n",
            "To become a professional banjo player, you need to spend thousands of hours practicing.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "[start] para un [UNK] [UNK] [UNK] hace diez años [end]\n",
            "-\n",
            "Tom could be Canadian.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "[start] tom podía ser canadiense [end]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "spa_vocab = target_vectorization.get_vocabulary()\n",
        "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
        "max_decoded_sentence_length = 20\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = target_vectorization([decoded_sentence])\n",
        "        next_token_predictions = seq2seq_rnn.predict(\n",
        "            [tokenized_input_sentence, tokenized_target_sentence])\n",
        "        sampled_token_index = np.argmax(next_token_predictions[0, i, :])\n",
        "        sampled_token = spa_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "    return decoded_sentence\n",
        "\n",
        "test_eng_texts = [pair[0] for pair in test_pairs]\n",
        "for _ in range(20):\n",
        "    input_sentence = random.choice(test_eng_texts)\n",
        "    print(\"-\")\n",
        "    print(input_sentence)\n",
        "    print(decode_sequence(input_sentence))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN + attention"
      ],
      "metadata": {
        "id": "TursiKAKGqPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Input, Attention, Concatenate\n",
        "from tensorflow.keras.models import Model\n"
      ],
      "metadata": {
        "id": "DDWNd-migo3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_seq = source_vectorization(train_english_texts).numpy()\n",
        "spanish_seq = target_vectorization(train_spanish_texts).numpy()\n",
        "\n",
        "english_vocab_size = source_vectorization.vocabulary_size()\n",
        "spanish_vocab_size = target_vectorization.vocabulary_size()\n"
      ],
      "metadata": {
        "id": "4g3FWnh-ggwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_length = 30\n",
        "encoder_input_data = pad_sequences(english_seq, maxlen=max_seq_length, padding='post')\n",
        "decoder_input_data = pad_sequences(spanish_seq, maxlen=max_seq_length, padding='post')\n",
        "decoder_target_data = np.zeros((len(spanish_seq), max_seq_length, spanish_vocab_size), dtype=\"float32\")\n",
        "\n",
        "for i, seq in enumerate(spanish_seq):\n",
        "    for j, word_index in enumerate(seq):\n",
        "        decoder_target_data[i, j, word_index] = 1.0"
      ],
      "metadata": {
        "id": "NtLxntNZeczM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_vocab = source_vectorization.get_vocabulary()\n",
        "source_index = dict(zip(source_vocab, range(len(source_vocab))))\n",
        "target_vocab = target_vectorization.get_vocabulary()\n",
        "target_index = dict(zip(target_vocab, range(len(target_vocab))))\n",
        "index_target = dict(enumerate(target_vocab))\n"
      ],
      "metadata": {
        "id": "CntLK_a7g5L3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 32\n",
        "hidden_units = 64\n",
        "\n",
        "encoder_inputs = Input(shape=(None,), name=\"english\")\n",
        "x = Embedding(vocab_size, embedding_dim)(encoder_inputs)\n",
        "encoder_outputs, state_h, state_c = LSTM(hidden_units, return_sequences=True, return_state=True)(x)\n",
        "\n",
        "decoder_inputs = Input(shape=(None,), name=\"spanish\")\n",
        "x = Embedding(vocab_size, embedding_dim)(decoder_inputs)\n",
        "decoder_lstm_out, _, _ = LSTM(hidden_units, return_sequences=True, return_state=True)(x, initial_state=[state_h, state_c])\n",
        "\n",
        "attention_out = Attention()([decoder_lstm_out, encoder_outputs])\n",
        "context = Concatenate(axis=-1)([decoder_lstm_out, attention_out])\n",
        "\n",
        "decoder_outputs = Dense(vocab_size, activation=\"softmax\")(context)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "Om2cnWTietyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_ds, validation_data=val_ds, epochs=20)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_td6hMMemuo",
        "outputId": "9194f38b-4265-40d5-f50a-b16e801ff07c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m5205/5205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 21ms/step - accuracy: 0.7055 - loss: 2.2679 - val_accuracy: 0.7573 - val_loss: 1.4809\n",
            "Epoch 2/20\n",
            "\u001b[1m5205/5205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 18ms/step - accuracy: 0.7652 - loss: 1.4326 - val_accuracy: 0.7931 - val_loss: 1.1870\n",
            "Epoch 3/20\n",
            "\u001b[1m5205/5205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 18ms/step - accuracy: 0.8020 - loss: 1.1301 - val_accuracy: 0.8233 - val_loss: 0.9922\n",
            "Epoch 4/20\n",
            "\u001b[1m5205/5205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 18ms/step - accuracy: 0.8327 - loss: 0.9144 - val_accuracy: 0.8410 - val_loss: 0.8741\n",
            "Epoch 5/20\n",
            "\u001b[1m5205/5205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 18ms/step - accuracy: 0.8535 - loss: 0.7662 - val_accuracy: 0.8514 - val_loss: 0.8036\n",
            "Epoch 6/20\n",
            "\u001b[1m5205/5205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 18ms/step - accuracy: 0.8683 - loss: 0.6615 - val_accuracy: 0.8582 - val_loss: 0.7592\n",
            "Epoch 7/20\n",
            "\u001b[1m5205/5205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 18ms/step - accuracy: 0.8793 - loss: 0.5843 - val_accuracy: 0.8624 - val_loss: 0.7324\n",
            "Epoch 8/20\n",
            "\u001b[1m5205/5205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 18ms/step - accuracy: 0.8882 - loss: 0.5251 - val_accuracy: 0.8651 - val_loss: 0.7164\n",
            "Epoch 9/20\n",
            "\u001b[1m5205/5205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 18ms/step - accuracy: 0.8960 - loss: 0.4781 - val_accuracy: 0.8668 - val_loss: 0.7080\n",
            "Epoch 10/20\n",
            "\u001b[1m5205/5205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 18ms/step - accuracy: 0.9029 - loss: 0.4397 - val_accuracy: 0.8678 - val_loss: 0.7044\n",
            "Epoch 11/20\n",
            "\u001b[1m5205/5205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 18ms/step - accuracy: 0.9088 - loss: 0.4082 - val_accuracy: 0.8686 - val_loss: 0.7042\n",
            "Epoch 12/20\n",
            "\u001b[1m5205/5205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 19ms/step - accuracy: 0.9138 - loss: 0.3821 - val_accuracy: 0.8689 - val_loss: 0.7056\n",
            "Epoch 13/20\n",
            "\u001b[1m5205/5205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 19ms/step - accuracy: 0.9181 - loss: 0.3600 - val_accuracy: 0.8689 - val_loss: 0.7086\n",
            "Epoch 14/20\n",
            "\u001b[1m5205/5205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 19ms/step - accuracy: 0.9217 - loss: 0.3413 - val_accuracy: 0.8690 - val_loss: 0.7127\n",
            "Epoch 15/20\n",
            "\u001b[1m5205/5205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 18ms/step - accuracy: 0.9251 - loss: 0.3251 - val_accuracy: 0.8691 - val_loss: 0.7190\n",
            "Epoch 16/20\n",
            "\u001b[1m5205/5205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 18ms/step - accuracy: 0.9279 - loss: 0.3110 - val_accuracy: 0.8689 - val_loss: 0.7263\n",
            "Epoch 17/20\n",
            "\u001b[1m5205/5205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 18ms/step - accuracy: 0.9304 - loss: 0.2989 - val_accuracy: 0.8687 - val_loss: 0.7346\n",
            "Epoch 18/20\n",
            "\u001b[1m5205/5205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 18ms/step - accuracy: 0.9326 - loss: 0.2880 - val_accuracy: 0.8681 - val_loss: 0.7440\n",
            "Epoch 19/20\n",
            "\u001b[1m5205/5205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 18ms/step - accuracy: 0.9348 - loss: 0.2781 - val_accuracy: 0.8680 - val_loss: 0.7502\n",
            "Epoch 20/20\n",
            "\u001b[1m5205/5205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 19ms/step - accuracy: 0.9366 - loss: 0.2692 - val_accuracy: 0.8678 - val_loss: 0.7597\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c3cb8ed2b90>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "spa_vocab = target_vectorization.get_vocabulary()\n",
        "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
        "max_decoded_sentence_length = 30\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
        "\n",
        "    # Инициализация начала перевода\n",
        "    decoded_sentence = \"[start]\"\n",
        "\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = target_vectorization([decoded_sentence])\n",
        "        next_token_predictions = model.predict(\n",
        "            {\n",
        "                \"english\": tokenized_input_sentence,\n",
        "                \"spanish\": tokenized_target_sentence\n",
        "            },\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        sampled_token_index = np.argmax(next_token_predictions[0, i, :])\n",
        "        sampled_token = spa_index_lookup.get(sampled_token_index, \"[UNK]\")\n",
        "\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "\n",
        "    return decoded_sentence.replace(\"[start] \", \"\").replace(\" [end]\", \"\")\n"
      ],
      "metadata": {
        "id": "QKuIKropm-Rf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_eng_texts = [pair[0] for pair in test_pairs]\n",
        "\n",
        "for _ in range(10):\n",
        "    input_sentence = random.choice(test_eng_texts)\n",
        "    print(\"-\" * 30)\n",
        "    print(\"Input:\", input_sentence)\n",
        "    print(\"Translation:\", decode_sequence(input_sentence))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEd3Z5OgnAXS",
        "outputId": "690b4d56-734e-45e0-da49-4097d6a73ded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------\n",
            "Input: Which do you prefer, white wine or red wine?\n",
            "Translation: qué prefieres el vino más rojo o de vino\n",
            "------------------------------\n",
            "Input: What is your emergency?\n",
            "Translation: cuál es tu estas oportunidad\n",
            "------------------------------\n",
            "Input: He was grateful for your help.\n",
            "Translation: Él fue criado por ti tu ayuda\n",
            "------------------------------\n",
            "Input: I'll meet them at six.\n",
            "Translation: me reuniré con los seis\n",
            "------------------------------\n",
            "Input: Where do they do that?\n",
            "Translation: dónde están hechos\n",
            "------------------------------\n",
            "Input: I asked him about the accident.\n",
            "Translation: le pedí acerca del accidente\n",
            "------------------------------\n",
            "Input: He got up at eight in the morning.\n",
            "Translation: Él se levantó a las ocho por la mañana\n",
            "------------------------------\n",
            "Input: He spoke well of her son.\n",
            "Translation: Él habló bien de su hijo\n",
            "------------------------------\n",
            "Input: I'm glad to hear it.\n",
            "Translation: me alegro de escuchar\n",
            "------------------------------\n",
            "Input: We must pay attention to the fact that no nation claimed sovereignty over this region.\n",
            "Translation: debemos prestar atención a ese hecho no está [UNK] con esta región que hay [UNK] esta pregunta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Aligment"
      ],
      "metadata": {
        "id": "IbgKLQlqtXKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Attention, Concatenate, Dense\n",
        "\n",
        "embedding_dim = 32\n",
        "hidden_units = 64\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(None,), name=\"english\")\n",
        "enc_emb = Embedding(vocab_size, embedding_dim)(encoder_inputs)\n",
        "encoder_outputs, state_h, state_c = LSTM(hidden_units, return_sequences=True, return_state=True)(enc_emb)\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = Input(shape=(None,), name=\"spanish\")\n",
        "dec_emb = Embedding(vocab_size, embedding_dim)(decoder_inputs)\n",
        "decoder_outputs, _, _ = LSTM(hidden_units, return_sequences=True, return_state=True)(dec_emb, initial_state=[state_h, state_c])\n",
        "\n",
        "# Attention\n",
        "attention_layer = Attention(name=\"attention_layer\")\n",
        "attention_output = attention_layer([decoder_outputs, encoder_outputs])\n",
        "concat_attention = Concatenate(axis=-1)([decoder_outputs, attention_output])\n",
        "\n",
        "decoder_dense = Dense(vocab_size, activation=\"softmax\")\n",
        "decoder_outputs = decoder_dense(concat_attention)\n",
        "\n",
        "# Основная модель\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Модель для получения attention-выходов\n",
        "attention_model = Model([encoder_inputs, decoder_inputs], attention_output)\n"
      ],
      "metadata": {
        "id": "d-nTnnr2taIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_ds, validation_data=val_ds, epochs=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgQRXsZrtekD",
        "outputId": "189e5d9e-0e9c-49c9-df62-f37000f15294"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5205/5205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1987s\u001b[0m 381ms/step - accuracy: 0.7282 - loss: 1.8048 - val_accuracy: 0.7603 - val_loss: 1.4326\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7fae7e0b7450>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Входное английское предложение\n",
        "test_sentence = \"We must pay attention to the fact that no nation claimed sovereignty\"\n",
        "\n",
        "max_decoded_sentence_length = 10\n",
        "# Преобразуем в токены\n",
        "tokenized_input = source_vectorization([test_sentence])\n",
        "decoded_sentence = \"[start]\"\n",
        "\n",
        "# Постепенно строим target-вход для декодера\n",
        "for i in range(max_decoded_sentence_length):\n",
        "    tokenized_target = target_vectorization([decoded_sentence])\n",
        "\n",
        "    # Получаем веса внимания с помощью attention_model\n",
        "    attention_weights = attention_model.predict([tokenized_input, tokenized_target], verbose=0)\n",
        "\n",
        "    # Получаем прогноз модели (основной)\n",
        "    preds = model.predict([tokenized_input, tokenized_target], verbose=0)\n",
        "    next_index = np.argmax(preds[0, i, :])\n",
        "    next_token = target_vectorization.get_vocabulary()[next_index]\n",
        "\n",
        "    decoded_sentence += \" \" + next_token\n",
        "    if next_token == \"[end]\":\n",
        "        break\n"
      ],
      "metadata": {
        "id": "PWmnUXj2_UwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_attention(attention, source_tokens, target_tokens):\n",
        "    attention = attention[0]  # убираем batch dim → (target_len, source_len)\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "    cax = ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "    ax.set_xticks(np.arange(len(source_tokens)))\n",
        "    ax.set_yticks(np.arange(len(target_tokens)))\n",
        "\n",
        "    ax.set_xticklabels(source_tokens, rotation=90)\n",
        "    ax.set_yticklabels(target_tokens)\n",
        "\n",
        "    ax.set_xlabel('Source')\n",
        "    ax.set_ylabel('Target')\n",
        "    plt.colorbar(cax)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "Ie4fUGsK_Ypm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_tokens = test_sentence.split()\n",
        "target_tokens = decoded_sentence.replace('[start]', '').replace('[end]', '').strip().split()\n",
        "\n",
        "plot_attention(attention_weights, source_tokens, target_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "id": "TqNx1OLX_njx",
        "outputId": "e38fe615-59a4-4d84-8ff2-a0fae1c024e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AG6PtZgW6zsr"
      },
      "source": [
        "# Трансформер"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tGA61kp6zsr"
      },
      "source": [
        "**Класс `TransformerDecoder`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OMLO8VV6zsr"
      },
      "outputs": [],
      "source": [
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1),\n",
        "             tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(\n",
        "                mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "        else:\n",
        "            padding_mask = mask\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs,\n",
        "            value=inputs,\n",
        "            key=inputs,\n",
        "            attention_mask=causal_mask)\n",
        "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=attention_output_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        attention_output_2 = self.layernorm_2(\n",
        "            attention_output_1 + attention_output_2)\n",
        "        proj_output = self.dense_proj(attention_output_2)\n",
        "        return self.layernorm_3(attention_output_2 + proj_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "su09Qb0f6zsr"
      },
      "source": [
        "**Слой PositionalEmbedding**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.ops as ops"
      ],
      "metadata": {
        "id": "Ue92g-VODiM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwK2UoHv6zsr"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=vocab_size, output_dim=embed_dim\n",
        "        )\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=embed_dim\n",
        "        )\n",
        "        self.sequence_length = sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = ops.shape(inputs)[-1]\n",
        "        positions = ops.arange(0, length, 1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return ops.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"sequence_length\": self.sequence_length,\n",
        "                \"vocab_size\": self.vocab_size,\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "            }\n",
        "        )\n",
        "        return config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDG4DsKo6zss"
      },
      "source": [
        "**End-to-end Трансформер**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            mask = mask[:, tf.newaxis, :]\n",
        "        attention_output = self.attention(\n",
        "            inputs, inputs, attention_mask=mask)\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config"
      ],
      "metadata": {
        "id": "P0urC6qKrupu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CkQTPIK6zss",
        "outputId": "d7457fde-9af2-46b9-ca66-11a3328f381b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:938: UserWarning: Layer 'transformer_encoder' (of type TransformerEncoder) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "embed_dim = 256\n",
        "dense_dim = 2048\n",
        "num_heads = 8\n",
        "\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"spanish\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1kYsxLc6zss"
      },
      "source": [
        "**Обучение**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36XcL2SS6zss",
        "outputId": "d2975e0b-9522-448f-c2e7-c3fc60c29386"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 64ms/step - accuracy: 0.1601 - loss: 4.3580 - val_accuracy: 0.2478 - val_loss: 2.2782\n",
            "Epoch 2/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 58ms/step - accuracy: 0.2507 - loss: 2.2767 - val_accuracy: 0.2745 - val_loss: 1.7672\n",
            "Epoch 3/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 59ms/step - accuracy: 0.2785 - loss: 1.7070 - val_accuracy: 0.2834 - val_loss: 1.5905\n",
            "Epoch 4/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 59ms/step - accuracy: 0.2924 - loss: 1.4112 - val_accuracy: 0.2874 - val_loss: 1.5238\n",
            "Epoch 5/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 59ms/step - accuracy: 0.3022 - loss: 1.2223 - val_accuracy: 0.2908 - val_loss: 1.4745\n",
            "Epoch 6/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 60ms/step - accuracy: 0.3095 - loss: 1.0939 - val_accuracy: 0.2925 - val_loss: 1.4730\n",
            "Epoch 7/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 58ms/step - accuracy: 0.3158 - loss: 0.9865 - val_accuracy: 0.2940 - val_loss: 1.4666\n",
            "Epoch 8/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 58ms/step - accuracy: 0.3209 - loss: 0.9067 - val_accuracy: 0.2947 - val_loss: 1.4749\n",
            "Epoch 9/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 57ms/step - accuracy: 0.3260 - loss: 0.8334 - val_accuracy: 0.2928 - val_loss: 1.5092\n",
            "Epoch 10/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 58ms/step - accuracy: 0.3296 - loss: 0.7819 - val_accuracy: 0.2946 - val_loss: 1.5136\n",
            "Epoch 11/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 58ms/step - accuracy: 0.3329 - loss: 0.7317 - val_accuracy: 0.2958 - val_loss: 1.5210\n",
            "Epoch 12/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 59ms/step - accuracy: 0.3362 - loss: 0.6908 - val_accuracy: 0.2957 - val_loss: 1.5439\n",
            "Epoch 13/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 58ms/step - accuracy: 0.3388 - loss: 0.6563 - val_accuracy: 0.2955 - val_loss: 1.5906\n",
            "Epoch 14/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 58ms/step - accuracy: 0.3416 - loss: 0.6240 - val_accuracy: 0.2943 - val_loss: 1.5890\n",
            "Epoch 15/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 59ms/step - accuracy: 0.3436 - loss: 0.5945 - val_accuracy: 0.2943 - val_loss: 1.6259\n",
            "Epoch 16/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 59ms/step - accuracy: 0.3455 - loss: 0.5709 - val_accuracy: 0.2962 - val_loss: 1.6135\n",
            "Epoch 17/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 58ms/step - accuracy: 0.3473 - loss: 0.5495 - val_accuracy: 0.2958 - val_loss: 1.6378\n",
            "Epoch 18/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 58ms/step - accuracy: 0.3493 - loss: 0.5254 - val_accuracy: 0.2960 - val_loss: 1.6562\n",
            "Epoch 19/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 59ms/step - accuracy: 0.3510 - loss: 0.5073 - val_accuracy: 0.2954 - val_loss: 1.6823\n",
            "Epoch 20/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 59ms/step - accuracy: 0.3521 - loss: 0.4923 - val_accuracy: 0.2955 - val_loss: 1.7112\n",
            "Epoch 21/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 59ms/step - accuracy: 0.3537 - loss: 0.4754 - val_accuracy: 0.2960 - val_loss: 1.7046\n",
            "Epoch 22/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 58ms/step - accuracy: 0.3554 - loss: 0.4556 - val_accuracy: 0.2959 - val_loss: 1.7510\n",
            "Epoch 23/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 58ms/step - accuracy: 0.3564 - loss: 0.4445 - val_accuracy: 0.2944 - val_loss: 1.7681\n",
            "Epoch 24/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 58ms/step - accuracy: 0.3572 - loss: 0.4336 - val_accuracy: 0.2946 - val_loss: 1.7865\n",
            "Epoch 25/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 58ms/step - accuracy: 0.3586 - loss: 0.4205 - val_accuracy: 0.2949 - val_loss: 1.7921\n",
            "Epoch 26/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 58ms/step - accuracy: 0.3596 - loss: 0.4080 - val_accuracy: 0.2948 - val_loss: 1.8197\n",
            "Epoch 27/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 58ms/step - accuracy: 0.3605 - loss: 0.3977 - val_accuracy: 0.2954 - val_loss: 1.8338\n",
            "Epoch 28/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 59ms/step - accuracy: 0.3614 - loss: 0.3894 - val_accuracy: 0.2938 - val_loss: 1.8485\n",
            "Epoch 29/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 57ms/step - accuracy: 0.3628 - loss: 0.3765 - val_accuracy: 0.2954 - val_loss: 1.8642\n",
            "Epoch 30/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 58ms/step - accuracy: 0.3633 - loss: 0.3664 - val_accuracy: 0.2950 - val_loss: 1.8804\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7946fb3375d0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "transformer.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"])\n",
        "transformer.fit(train_ds, epochs=30, validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wcgnjw6X6zss"
      },
      "source": [
        "**Пример перевода**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMRfu7HO6zss",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06df2714-9e0b-4875-da39-9341635bcdba",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "He will have no chance of winning her heart.\n",
            "[start] Él no tendré oportunidad de ganar su corazón [end]\n",
            "-\n",
            "She has convulsions.\n",
            "[start] ella tiene [UNK] [end]\n",
            "-\n",
            "It wasn't as expensive as I expected.\n",
            "[start] no era tan caro como esperaba [end]\n",
            "-\n",
            "It took me several hours to write it.\n",
            "[start] me tomó varias horas escribirlo [end]\n",
            "-\n",
            "She went out of the room.\n",
            "[start] salió de la habitación [end]\n",
            "-\n",
            "I needed it.\n",
            "[start] yo necesité [end]\n",
            "-\n",
            "He hasn't done anything.\n",
            "[start] no ha hecho nada [end]\n",
            "-\n",
            "I can't hear what they're saying.\n",
            "[start] no puedo oír lo que dicen [end]\n",
            "-\n",
            "Tom is paying attention to his budget.\n",
            "[start] tom le está poniendo atención a su presupuesto [end]\n",
            "-\n",
            "Tom called Mary to tell her he'd be late.\n",
            "[start] tom llamó a mary para decirle que él llegó tarde [end]\n",
            "-\n",
            "I like to talk.\n",
            "[start] me gusta hablar [end]\n",
            "-\n",
            "I don't want to buy anything like that.\n",
            "[start] no quiero comprar nada como eso [end]\n",
            "-\n",
            "We live near a big library.\n",
            "[start] vivimos cerca de una casa larga [end]\n",
            "-\n",
            "It just came out.\n",
            "[start] acaba de salir [end]\n",
            "-\n",
            "Tom changed.\n",
            "[start] tomás cambió [end]\n",
            "-\n",
            "I can show the documents to you.\n",
            "[start] puedo mostrarte los documentos [end]\n",
            "-\n",
            "I have to go there for my father.\n",
            "[start] tengo que ir allí para mi padre [end]\n",
            "-\n",
            "You don't seem very pleased.\n",
            "[start] no pareces muy contento [end]\n",
            "-\n",
            "Tom brought a gift for Mary.\n",
            "[start] tom trajo un regalo a mary [end]\n",
            "-\n",
            "She was cooking dinner at that time.\n",
            "[start] ella estaba cocinando en la cena [end]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "spa_vocab = target_vectorization.get_vocabulary()\n",
        "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
        "max_decoded_sentence_length = 20\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = target_vectorization(\n",
        "            [decoded_sentence])[:, :-1]\n",
        "        predictions = transformer(\n",
        "            [tokenized_input_sentence, tokenized_target_sentence])\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        sampled_token = spa_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "    return decoded_sentence\n",
        "\n",
        "test_eng_texts = [pair[0] for pair in test_pairs]\n",
        "for _ in range(20):\n",
        "    input_sentence = random.choice(test_eng_texts)\n",
        "    print(\"-\")\n",
        "    print(input_sentence)\n",
        "    print(decode_sequence(input_sentence))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}